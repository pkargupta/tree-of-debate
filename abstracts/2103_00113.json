{
    "title": "Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning",
    "abstract": "Anomaly detection on attributed networks attracts considerable research interests due to wide applications of attributed networks in modeling a wide range of complex systems. Recently, the deep learning-based anomaly detection methods have shown promising results over shallow approaches, especially on networks with high-dimensional attributes and complex structures. However, existing approaches, which employ graph autoencoder as their backbone, do not fully exploit the rich information of the network, resulting in suboptimal performance. Furthermore, these methods do not directly target anomaly detection in their learning objective and fail to scale to large networks due to the full graph training mechanism. To overcome these limitations, in this paper, we present a novel contrastive self-supervised learning framework for anomaly detection on attributed networks. Our framework fully exploits the local information from network data by sampling a novel type of contrastive instance pair, which can capture the relationship between each node and its neighboring substructure in an unsupervised way. Meanwhile, a well-designed graph neural network-based contrastive learning model is proposed to learn informative embedding from high-dimensional attributes and local structure and measure the agreement of each instance pairs with its outputted scores. The multi-round predicted scores by the contrastive learning model are further used to evaluate the abnormality of each node with statistical estimation. In this way, the learning model is trained by a specific anomaly detection-aware target. Furthermore, since the input of the graph neural network module is batches of instance pairs instead of the full network, our framework can adapt to large networks flexibly. Experimental results show that our proposed framework outperforms the state-of-the-art baseline methods on all seven benchmark datasets.",
    "introduction": "Attributed networks (a.k.a. attributed graphs), where nodes with attributes indicate real-world entities and links indicate the relationship between entities, are ubiquitous in various scenarios, including finance (trading networks) [1], social media (social networks) [2], [3], and e-commerce (itemuser networks) [4], [5]. To utilize attributed network data to solve practical problems, a wide variety of graph analysis tasks have attracted significant research interests in recent years, such as node classification [6], [7], graph classification [8], [9], and link prediction [10], [11]. Among these tasks, anomaly detection task on attributed networks is a vital research problem. Aiming to detect the instances that significantly deviate from the majority of instances [12] (in attributed networks, the data instances are nodes generally), anomaly detection has significant implications in many security-related applications, e.g., fraud detection and social spam detection [13]. However, detecting anomalies effectively on attributed networks is not trivial due to the diversity of anomalies and the lack of supervision. Since attributed networks have both attribute information as well as structural information, they usually contain different types of anomalies. Figure 1 provides an example to illustrate two basic types of anomalies: structural anomaly and contextual anomaly. The attribute information of the structural anomalies is often normal, while they have several abnormal links to other nodes. The contextual anomalies, differently, have natural neighboring structures but their attributes are corrupted (noisy or entirely different from all neighbors). Such diversity makes it difficult to apply anomaly detection methods for attribute-only data (e.g., OC-SVM [14]) or plain networks (e.g., LOF [15]) to attributed networks directly. Therefore, an efficient anomaly detection approach should consider multiple patterns of anomalies. Moreover, resulting from the prohibitive cost for accessing ground-truth labels of anomalies, anomaly detection on attributed networks is predominately carried out in an unsupervised manner [13], [16]. That is to say, the algorithm has to conclude the normal pattern of data from the corrupted networks without supervision. Hence, a key is to fully and reasonably exploit existing information from attributed network data. Recently, various methods have been proposed to deal with the anomaly detection task for attributed networks. The shallow methods, including AMEN [16], Radar [17] and ANOMALOUS [18], leverage shallow learning mechanisms (e.g. ego-network analysis, residual analysis or CUR decomposition) to detect anomalies. Unfortunately, these models cannot fully address the computational challenge on attributed networks and fail to capture the complex interactions between different information modalities due to limitations of shallow mechanisms, especially when the feature is high-dimensional [13]. With the rocketing growth of deep learning for anomaly detection [12], [19], [20], [21], researchers also present deep neural networks-based methods to solve the anomaly detection problem on attributed networks. DOMINANT [13] is one of the representative methods. It constructs a graph autoencoder to reconstruct the attribute and structure information simultaneously, and the abnormality is evaluated by reconstruction error. SpecAE [22] also leverages graph autoencoder to extract low-dimensional embedding, and carries out detection via density estimation. Although existing deep learning-based methods [13], [22] have achieved considerable performance for anomaly detection on graphs, they still have several shortcomings, largely attributed to the autoencoder backbone in their architectures. First, autoencoders aim to learn the latent representation by reconstructing the original data instead of detecting the anomaly itself. Although the anomaly scores can be computed according to reconstruction errors [13], this kind of methods can only achieve suboptimal performance due to the fact that they do not target directly the anomaly detection objective. Second, autoencoder-based methods may not able to fully exploit the rich information of the attributed graph for effective graph representation learning. Specifically, autoencoders simply rebuild the original data and they do not have any refinement for data. However, recent works [23], [24], [25] have shown that more useful information can be mined in an unsupervised way if we design certain pretext tasks carefully based on augmented data. Third, graph autoencoder is the bottleneck to carry out anomaly detection on largescale networks. Generally, the graph convolution operation in graph autoencoder needs to input and reconstruct the full networked data, which is unfeasible due to the explosive memory requirements when the network is large. As an alternative unsupervised learning technique, selfsupervised contrastive learning is a promising solution to address the aforementioned limitations. By learning to contrast the elaborate instance pairs, the model can acquire informative knowledge without manual labels. Contrastive self-supervised learning has nice properties for anomaly detection task. First, contrastive learning mainly studies the matching of pairs of instances, which offers helpful information for anomaly detection. For the normal instance in graphs, there is a potential matching pattern between each node and its neighbors, e.g., the homophily hypothesis. The anomalies, on the opposite, often present when there is an inconsistency/mismatch between attributes and structure, which violates the original matching pattern of networks. Moreover, different types of anomalies have different manners of mismatching: in Figure 1, the structural anomaly has individual abnormal links with uncorrelated nodes, which is partial inconsistency; the contextual anomaly, differently, has mismatched attributes with all neighbors. Contrastive learning, naturally, is capable to learn the matching patterns and capture various mismatching patterns via its intrinsic discriminative mechanism. Second, contrastive learning models provide a specific predicted score to measure the agreement between the elements in each instance pair, and the scale is highly related to the abnormality of instance. Since anomaly detection methods usually output a list of scores or a ranking to represent the abnormality of each node, the predicted scores of contrastive learning model can be utilized for anomaly detection directly. In this way, we can train the model via an objective that is highly relevant to anomaly detection. In this paper, we propose a novel Contrastive self-supervised Learning framework for Anomaly detection on attributed networks (CoLA for abbreviation). By sampling the welldesigned instance pairs from the full network and using them to train the contrastive learning model, the information of network is exploited better. Concretely, our framework focuses on modeling the relationship between each node and its partial neighboring substructure, which can expose the various type of anomalies within networks. Meanwhile, our CoLA framework is trained with a direct target to assist the anomaly detection task. We set the learning objective of our model to discriminate the agreement between the elements within the instance pairs, and the results can be further used to evaluate the abnormality of nodes. Besides, by splitting the network into separated lightweight instance pairs, our anomaly detection framework is compatible with large-scale networks. Specifically, our framework does not need to run graph convolution on full networks, so it successfully avoids the memory explosion problem. To summarize, the main contributions are as follows: We propose a contrastive self-supervised learning framework, CoLA, for the anomaly detection problem on attributed networks. To the best of our knowledge, this is the first contrastive self-supervised learning-based method for graph anomaly detection.IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 3 We present a novel type of contrastive instance pair, “target node v.s. local subgraph”, for attributed networks to adapt to the anomaly detection task, which efficiently captures the local information of a node and its neighboring substructure. We design a contrastive learning model to learn the representative information from the node-subgraph instance pairs and provide discriminative scores for abnormality ranking. The proposed learning model is friendly to largescale networked data. We conduct extensive experiments on various datasets to demonstrate the effectiveness of CoLA and its superiority compared with a range of baseline methods. The rest of this paper is organized as follows. In Section II, we first review the related works. Then, the preliminary definitions and notations are introduced in Section III. Section IV illustrates the overall pipeline and the components of our framework in detail. After that, we analyze the experimental results in Section V and then conclude our work in section VI.",
    "arxiv_key": "2103_00113"
}