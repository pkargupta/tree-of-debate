{
    "title": "DELIFT: Data Efficient Language model Instruction Fine-Tuning",
    "abstract": "Fine-tuning large language models (LLMs) is essential for enhancing their performance on specific tasks but is often resource-intensive due to redundant or uninformative data. To address this inefficiency, we introduce DELIFT (Data Efficient Language model Instruction Fine-Tuning), a novel algorithm that systematically optimizes data selection across the three key stages of fine-tuning: (1) instruction tuning, (2) task-specific fine-tuning (e.g., reasoning, question-answering), and (3) continual fine-tuning (e.g., incorporating new data versions). Unlike existing methods that focus on single-stage optimization or rely on computationally intensive gradient calculations, DELIFT operates efficiently across all stages. Central to our approach is a pairwise utility metric that quantifies how beneficial a data sample is for improving the model's responses to other samples, effectively measuring the informational value relative to the model's current capabilities. By leveraging different submodular functions applied to this metric, DELIFT selects diverse and optimal subsets that are useful across all stages of fine-tuning. Experiments across various tasks and model scales demonstrate that DELIFT can reduce the fine-tuning data size by up to 70% without compromising performance, offering significant computational savings and outperforming existing methods in both efficiency and efficacy.",
    "introduction": "Fine-tuning large language models (LLMs) is pivotal for adapting these powerful architectures (Devlin et al., 2019; Brown et al., 2020a; Touvron et al., 2023) to specialized tasks such as intricate reasoning, precise question-answering, and the seamless integration of new information (Ouyang et al., 2022). This transformation—from a general-purpose model to a task-specific agent—heavily relies on the quality and nature of the data employed during fine-tuning, which critically determines the model's subsequent performance (Wei et al., 2022; Zhou et al., 2023; Hoffmann et al., 2024). The effectiveness of fine-tuning hinges on the quality, diversity, and relevance of the selected data (Gururangan et al., 2020; Wei et al., 2022; Zhou et al., 2023). High-quality data ensures accurate learning, diverse data enhances generalization, and relevant data aligns the model's capabilities with specific application needs. However, optimizing data selection across different fine-tuning phases remains a significant challenge, leading to our central research question: How can we create a unified framework for efficient data selection across all fine-tuning stages of LLMs, while optimizing performance and maximizing data efficiency? To address this challenge, we present DELIFT (Data Efficient Language model Instruction Fine- Tuning), a novel, unified, and computationally efficient algorithm engineered to optimize data selection across all stages of the fine-tuning process. The key innovation of DELIFT lies in its pairwise utility metric, which assesses the informational value of data samples relative to both the model's current capabilities and other samples within the dataset. This metric, combined with submodular optimization techniques, allows DELIFT to efficiently select optimal data subsets that precisely address the model's learning requirements without incurring unnecessary computational costs. 1 arXiv:2411.04425v2 [cs.CL] 10 Nov 2024The typical fine-tuning process comprises three key stages: 1. Instruction Tuning: Enhances the model's ability to follow general instructions (Mishra et al., 2022; Wei et al., 2022; Longpre et al., 2023); 2. Task-Specific Fine-Tuning: Refines the model's expertise in specific domains (Gururangan et al., 2020; Cobbe et al., 2021); 3. Continual Fine-tuning: Enables the model to integrate new information while mitigating catastrophic forgetting (Madotto et al., 2021; Wu et al., 2024). DELIFT is able to optimize data selection processes across all three stages. Additionally, DELIFT offers significant benefits for In-Context Learning (ICL) (Brown et al., 2020b; Xue et al., 2024). By utilizing the selected subsets as the ICL example pool, DELIFT achieves similar or better performance compared to using the entire dataset, thereby enhancing data efficiency in ICL scenarios. This dual functionality is empirically validated in our experimental results. Existing data selection methodologies often fail to address the nuanced requirements of the aforementioned distinct fine-tuning stages. Many approaches are tailored to a single stage, lacking the adaptability needed for comprehensive fine-tuning (Xia et al., 2024; Liu et al., 2024; Bukharin & Zhao, 2024; Chen et al., 2024). Others depend on computationally intensive procedures, such as exhaustive gradient computations, rendering them impractical for large-scale models and datasets (Killamsetty et al., 2021b;a; Xia et al., 2024; Zhang et al., 2024). Additionally, some methods utilize features obtained from an independent model that are not specifically aligned with the model undergoing fine-tuning, reducing their effectiveness (Killamsetty et al., 2023; Liu et al., 2024; Bukharin & Zhao, 2024; Chen et al., 2024; Du et al., 2023). DELIFT addresses these limitations by adapting to the unique requirements of each fine-tuning stage. 1. Instruction Tuning: Selects diverse data to enhance general instruction-following capabilities; 2. Task-Specific Fine-Tuning: Prioritizes data that is aligned with the target task, to refine specialized expertise; 3. Continual Fine-tuning: Identifies novel, complementary information to expand the model's knowledge base while safeguarding against catastrophic forgetting. Figure 1 illustrates how DELIFT optimizes data selection across these stages, demonstrating the selection and pruning processes in each fine-tuning phase. By leveraging submodular optimization techniques (Fujishige, 2005; Bilmes, 2022) and submodular information measures (Iyer et al., 2021), DELIFT efficiently selects optimal data subsets that precisely address the model's learning requirements without incurring unnecessary computational costs. This approach effectively balances data utility and computational efficiency. Our key contributions are as follows: 1) Versatile Pairwise Utility Metric: A novel, easy-to-compute metric for assessing data informativeness, incorporating model feedback applicable across all fine-tuning stages. 2) Unified Data Selection Algorithm: DELIFT systematically optimizes data selection for instruction tuning, task-specific fine-tuning, and continual fine-tuning within a single framework. 3) Computational Efficiency: Circumvents resource-intensive operations, ensuring scalability to large datasets and models. DELIFT achieves at least 70% reduction in computational time compared to gradient-based methods on benchmark tasks. 4) Enhanced Performance with Reduced Data: Demonstrates the ability to reduce fine-tuning data size by up to 70% without compromising performance, and achieves comparable efficacy as to utilizing the full dataset. 5) Improvement over Existing Methods: Outperforms current data selection techniques by up to 26% in effectiveness across diverse tasks and model scales (see Section 4). The remainder of this paper is organized as follows: Section 2 provides background on fine-tuning LLMs and reviews related work. Section 3 details the methodology behind DELIFT, including the development of our pairwise utility metric and the submodular optimization process. Section 4 presents experimental results that showcase the effectiveness and efficiency of our method. Section 5 discusses the implications of our findings and potential future directions. Finally, we release our code base for further research.",
    "arxiv_key": "2411_04425"
}