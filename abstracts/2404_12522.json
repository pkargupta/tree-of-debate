{
    "title": "Neural Active Learning Beyond Bandits",
    "abstract": "We study both stream-based and pool-based active learning with neural network approximations. A recent line of works proposed bandit-based approaches that transformed active learning into a bandit problem, achieving both theoretical and empirical success. However, the performance and computational costs of these methods may be susceptible to the number of classes, denoted as K, due to this transformation. Therefore, this paper seeks to answer the question: \"How can we mitigate the adverse impacts of K while retaining the advantages of principled exploration and provable performance guarantees in active learning?\" To tackle this challenge, we propose two algorithms based on the newly designed exploitation and exploration neural networks for stream-based and pool-based active learning. Subsequently, we provide theoretical performance guarantees for both algorithms in a non-parametric setting, demonstrating a slower error-growth rate concerning K for the proposed approaches. We use extensive experiments to evaluate the proposed algorithms, which consistently outperform state-of-the-art baselines.",
    "introduction": "Active learning is one of the primary areas in machine learning to investigate the learning technique on a small subset of labeled data while acquiring good generalization performance compared to passive learning [ 19 ]. There are mainly two settings of active learning: stream-based and pool-based settings. For the stream-based setting, the learner is presented with an instance drawn from some distribution in each round and is required to decide on-the-fly whether or not to query the label from the oracle. For the pool-based setting, the learner aims to select one or multiple instances from the unlabeled pool and hand them over to the oracle for labeling. It repeats this process until the label budget is exhausted [51]. The essence of active learning is to exploit the knowledge extracted from labeled instances and explore the unlabeled data to maximize information acquisition for long-term benefits. Using neural networks (NNs) to perform active learning has been explored extensively in recent works [48 ; 52 ; 56 ; 6 ]. However, they often lack a provable performance guarantee despite strong empirical performance. To address this issue, a recent line of works [58 ; 14 ] proposed the banditbased approaches to solve the active learning problem, which are equipped with principled exploration and theoretical performance guarantee. In contextual bandits [38 ; 68], the learner is presented with K arms (context vectors) and required to select one arm in each round. Then, the associated reward is observed. [58; 14] transformed the online K-class classification into a bandit problem. Specifically, in one round of stream-based active learning, a data instance xt ∈ Rd is transformed into K long vectors corresponding to K arms, matching K classes: xt,1 = [x⊤ t , 0⊤, · · · , 0⊤]⊤, . . . , xt,K = [0⊤, · · · , 0⊤, x⊤ t ]⊤, where xt,k ∈ RdK , k ∈ [K]. Then, the learner uses an NN model to calculate a score for each arm and selects an arm based on these scores. The index of the selected arm represents the index of the predicted class. This design enables researchers to utilize the exploration strategy and analysis in contextual bandits to solve the active learning problem. Note [58; 14 ] can only handle the stream-based setting of active learning. However, bandit-based approaches bear the following two limitations. First, as the instance xt is transformed into K arms, it is required to calculate a score for all K arms respectively, producing a cost of K times forward-propagation computation of neural networks. This computation cost is scaled by K. Second, the transformed long vector (arm) has (Kd) dimensions, in contrast to the d dimensions of the original instance as the input of the NN model. This potentially amplifies the effects of K on an active learning algorithm's performance. We empirically evaluate [58; 14 ] as shown in Table 1. The results indicate a noticeable degradation in both test accuracy and running time as K increases. In response, in this paper, we aim to mitigate the adverse effects of K on the bandit-based approach in active learning. Our methods are built upon and beyond [ 14 ]. [ 14 ] adopted the idea of [13 ] to employ two neural networks, one for exploitation and another for exploration. As previously mentioned, these two neural networks take the transformed Kd-dimension arm as input. Moreover, in each round, [ 14] decomposed the label vector yt ∈ {0, 1}K into K rewards (scalars), necessitating the training of two neural networks K times for each arm. Next, we summarize our key ideas and contributions to reduce the input dimension back to d and the number of forward propagations to 1 in each round while preserving the essence of exploitation and exploration of neural networks. Methodology. (1) We extend the loss function in active learning from 0-1 loss to Bounded loss, which is more flexible and general. Instead, [58; 14 ] restricted the loss to be 0-1 loss, because they had to define the reward of each class (arm) due to their bandit-based methodology. (2) We re-designed the input and output exploitation and exploration neural networks to directly take the d-dimension instance as input and output the predicted probabilities for K classes synchronously, mitigating the curse of K. The connection between exploitation and exploration neural networks is also reconstructed beyond the standard bandit setting. In other words, we avoid the transformation of active learning to the standard bandit setting. This is the first main contribution of this paper. (3) To facilitate efficient and effective exploration, we introduce the end-to-end embedding (Definition 4.1) as the input of the exploration neural network, which removes the dependence of the input dimension while preserving the essential information. (4) In addition to our proposed stream-based algorithm, referred to NEURONAL-S, we also propose a pool-based active learning algorithm, NEURONAL-P. We bring the redesigned exploitation and exploration network into pool-based setting and propose a novel gap-inverse-based selection strategy tailored for pool-based active learning. This is our second main contribution. Note that the stream-based algorithms cannot be directly converted into the pool-based setting, as discussed in Appendix B. Theoretical analysis. We provide the regret upper bounds for the proposed stream-based algorithm under low-noise conditions on the data distribution. Our results indicate the cumulative regret of NEURONAL-S grows slower than that of [ 58] concerning K by a multiplicative factor at least O(pT log(1 + λ0)) and up to eO(√md), where λ0 is the smallest eigenvalue of Neural Tangent Kernel (NTK) and m is the width of the neural network. This finding helps explain why our algorithms outperform the bandit-based algorithms, particularly when K is large, as shown in Table 1. In the binary classification task, our regret bounds directly remove the dependence of effective dimension  ̃d, which measures the actual underlying dimension in the RKHS space spanned by NTK, discussed in Sec. 5. We also provide a performance analysis for the proposed pool-based algorithm in the non-parametric setting, tailored for neural network models. In contrast, previous works focus on the regime either in parametric settings that require a finite VC dimension [31] or a linear mapping function assumption [ 8 ; 64 ; 28 ]. The above theoretical results are our third main contribution. In addition, Empirical evaluation. In the end, we perform extensive experiments to evaluate the proposed algorithms for both stream-based and pool-based algorithms compared to state-of-the-art baselines. Our evaluation encompasses various metrics, including test accuracy and running time, and we have carried out ablation studies to investigate the impact of hyper-parameters and label budgets. This is our fourth main contribution.",
    "arxiv_key": "2404_12522"
}