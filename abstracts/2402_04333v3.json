{
    "title": "LESS: Selecting Influential Data for Targeted Instruction Tuning",
    "abstract": "Instruction tuning has unlocked powerful capabilities in large language models (LLMs), using combined datasets to develop general-purpose chatbots. However, real-world applications often require a specialized suite of skills (e.g., reasoning). The challenge lies in identifying the most relevant data from these extensive datasets to effectively develop specific capabilities, a setting we frame as targeted instruction tuning. We propose LESS, an optimizer-aware and practically efficient algorithm to estimate data influences and perform Low-rank gradiEnt Similarity Search for instruction data selection. Crucially, LESS adapts existing influence formulations to work with the Adam optimizer and variable-length instruction data. LESS first constructs a highly reusable and transferable gradient datastore with low-dimensional gradient features and then selects examples based on their similarity to few-shot examples embodying a specific capability. Experiments show that training on a LESS-selected 5% of the data can often outperform training on the full dataset across diverse downstream tasks. Furthermore, the selected data is highly transferable: smaller models can be leveraged to select useful data for larger models and models from different families. Our qualitative analysis shows that our method goes beyond surface form cues to identify data that exemplifies the necessary reasoning skills for the intended downstream application. To facilitate future work, we release code and data at princetonnlp/LESS.",
    "introduction": "nstruction tuning has made large language models (LLMs) adept at following human instructions (Ouyang et al., 2022) as versatile chatbots (OpenAI, 2022; 2023; Anthropic, 2023; Google, 2023). Recent efforts curating highly diverse and wide-ranging instruction tuning datasets (Taori et al., 2023; Wang et al.; Mukherjee et al., 2023; Xu et al., 2023, inter alia) induce remarkably strong generalization even from a small number of examples (Zhou et al., 2023). Regardless, it remains an open problem to understand how to best utilize these various datasets. Many real-world applications call for cultivating a specific suite of capabilities in LLMs (e.g., reasoning skills). However, training LLMs with mixed instruction tuning datasets can hinder the development of these specific capabilities. For example, Wang et al. (2023b) demonstrates that LLMs trained on a mix of instruction tuning datasets exhibit worse performance than those trained on a subset of the data. Additionally, considering the broad spectrum of user queries and the multitude of skills required to respond to them, there may not always be enough in-domain data available. Therefore, we hope to be able to effectively use the general instruction tuning data to improve specific capabilities. We frame this setting as targeted instruction tuning: Given just a handful of examples embodying a specific capability, how can we effectively select relevant fine-tuning data from a large collection of instruction datasets? We approach this problem by prioritizing training on data that directly minimizes loss on a target task instead of relying on surface form features (Gururangan et al., 2020; Xie et al., 2023b). Inspired by past works estimating the influence of individual training datapoints with gradient information (Pruthi et al., 2020; Han et al., 2023), we design an optimizer-aware approach to select such data. However, straightforward application of this influence formulation faces several challenges unique to the instruction tuning setting: (1) LLMs are traditionally fine-tuned with the Adam optimizer (Kingma & Ba, 2015) instead of the canonical SGD optimizer; (2) using sequence-level gradients of variable-length instruction data can derail the influence estimation; and (3) the large number of trainable parameters in LLMs makes the computation and storage of gradient information extremely resource-intensive. 1 arXiv:2402.04333v3 [cs.CL] 13 Jun 2024LESS: Selecting Influential Data for Targeted Instruction Tuning We address these concerns in LESS, an algorithm that performs Low-rank gradiEnt Similarity Search to select relevant instruction tuning data for a target application, which exhibits the following properties: 1. Compatible with instruction tuning with Adam (§2 and §3): LESS adapts the gradient features from classical influence formulations (Pruthi et al., 2020) to work with the Adam optimizer and variable-length instruction data. The optimization insights and influence formulation may be of independent interest as well. 2. Efficient (§4.1): LESS uses LoRA (Hu et al., 2021) and random projections (Johnson & Lindenstrauss, 1984) to construct a gradient datastore with lowdimensional, easily manipulable gradient features that permit efficient and effective dataset selection. The gradient datastore can be reused for new target tasks. 3. Transferable (§5.3): Data selected using small models' gradient features induce strong performance in large models and models from different families, adding to the efficiency of LESS (Table 2). 4. Interpretable (§6.2): Qualitative analysis shows that LESS selects data with similar reasoning and skill types as the target task, whereas existing approaches often select data based on surface form cues (e.g., language or topic). We evaluate our approach on three diverse downstream datasets—MMLU (Hendrycks et al., 2020), TY- DIQA (Clark et al., 2020), and BBH (Suzgun et al., 2023)—each containing distinct subtasks that effectively simulate targeted instruction tuning scenarios. Results show that LESS often selects a small subset of the data (5%) that outperforms training on the full dataset, and the selected subset remains universally effective across model scales and families (Table 2). Comparisons with other data selection methods show that LESS is the only consistently effective approach, justifying its relatively high computational cost.",
    "arxiv_key": "2402_04333v3"
}